{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 2010 Final Project - Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predictors ##\n",
    "trips_data = pd.read_csv(\"Raw_Data/Trips_by_Distance.csv\")\n",
    "covid_19_data = pd.read_csv(\"Raw_Data/all-states-history-correct-range.csv\")\n",
    "\n",
    "## Response ##\n",
    "# Starts Apr 23, Ends Nov 9\n",
    "anxiety_depression_data = pd.read_csv(\"Raw_Data/Indicators_of_Anxiety_or_Depression_Based_on_Reported_Frequency_of_Symptoms_During_Last_7_Days.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean trip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reduce dimensionality from county -> state \n",
    "td = trips_data.groupby(by = ['Date', 'State Postal Code']).sum().drop(columns= ['State FIPS', 'County FIPS']).reset_index()\n",
    "td['Period'] = np.floor(td.index / 51 / 7)\n",
    "# Create Period column\n",
    "td2 = td.groupby(by = ['Period', 'State Postal Code']).mean().reset_index()\n",
    "td2[\"Period\"] = td2[\"Period\"] - 1\n",
    "td2.loc[td2[\"Period\"] == -1,\"Period\"] = 0\n",
    "# Index 1-11 are 1 week\n",
    "# Index 12-16 are break\n",
    "for i in range(12, 17):\n",
    "    td2.loc[td2[\"Period\"] == i,\"Period\"] = 12\n",
    "\n",
    "# Index 17|18, 19|20, 21|22, 23|24, 25|26, 27|28 are one time period\n",
    "# Thus this code makes the two week time fromes to one period\n",
    "period = 13\n",
    "for i in range(0, 12, 2):\n",
    "    week = i + 17\n",
    "    td2.loc[td2[\"Period\"] == week,\"Period\"] = period\n",
    "    td2.loc[td2[\"Period\"] == week + 1,\"Period\"] = period\n",
    "    period += 1\n",
    "\n",
    "# Sum the period and state to get the trips per time period\n",
    "td2 = td2.groupby(by= [\"Period\", \"State Postal Code\"]).mean().reset_index()\n",
    "\n",
    "# Remove 12th time period because it is the break\n",
    "td2 = td2[td2['Period'] != 12.0]\n",
    "\n",
    "# Increment all the time periods before 12 by 1\n",
    "td2['Period'] = td2.apply(lambda x:\n",
    "                        x['Period']+1\n",
    "                        if x['Period'] < 12 \n",
    "                        else\n",
    "                        x['Period'], axis=1)\n",
    "\n",
    "trip_df = td2.copy()\n",
    "\n",
    "# Rename State column to align with other data\n",
    "trip_df['State'] = trip_df['State Postal Code']\n",
    "trip_df = trip_df.drop('State Postal Code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df.to_csv(\"Clean_Data/clean_trip_data.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean COVID-19 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare covid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take desired columns from the data\n",
    "valuable_cols = ['state', 'date', 'death', 'deathConfirmed', \n",
    "                 'hospitalizedCurrently', 'positiveCasesViral', \n",
    "                 'positiveIncrease', 'totalTestsPeopleViral', \n",
    "                 'totalTestsPeopleViralIncrease', 'totalTestsViral', 'positiveTestsViral']\n",
    "covid_data = covid_19_data.copy()[valuable_cols]\n",
    "\n",
    "# Convert string to datetime\n",
    "covid_data['date'] = covid_data['date'].astype('datetime64[ns]')\n",
    "\n",
    "# 50 States + 1 Federal District (DC: District of Columbia)\n",
    "remove_states = ['AS', 'PR', 'GU', 'MP', 'VI']\n",
    "# AS: American Samoa\n",
    "# PR: Puerto Rico\n",
    "# GU: Guam\n",
    "# MP: Northern Mariana Islands\n",
    "# VI: US Virgin Islands\n",
    "states = list(set(covid_data['state'].values))\n",
    "final_states = [item for item in states if item not in remove_states]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Time Period column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These ranges match the time periods within our response data.\n",
    "ranges_list = ['4/23/2020-5/5/2020', '5/7/2020-5/12/2020', '5/14/2020-5/19/2020', '5/21/2020-5/26/2020',\n",
    "               '5/28/2020-6/2/2020', '6/4/2020-6/9/2020', '6/11/2020-6/16/2020', '6/18/2020-6/23/2020',\n",
    "               '6/25/2020-6/30/2020', '7/2/2020-7/7/2020', '7/9/2020-7/14/2020', '7/16/2020-7/21/2020',                  \n",
    "               '8/19/2020-8/31/2020', '9/2/2020-9/14/2020', '9/16/2020-9/28/2020', '9/30/2020-10/12/2020', \n",
    "               '10/14/2020-10/26/2020', '10/28/2020-11/9/2020']\n",
    "\n",
    "# Convert ranges_list to a list of lists of start and end datetimes\n",
    "period_list = []\n",
    "for r in ranges_list: # '4/23/2020-5/5/2020'\n",
    "    r_list = []\n",
    "    for date_str in r.split('-'): # [4/23/2020, 5/5/2020]\n",
    "        date = dt.datetime.strptime(date_str, '%m/%d/%Y').date() # 4/23/2020 -> datetime\n",
    "        r_list.append(date) # [start,end]\n",
    "    period_list.append(r_list) # [[start,end],[start,end]..]\n",
    "\n",
    "# Create Time Period column\n",
    "time_periods = [] \n",
    "    # 1-n: respective period by number \n",
    "    # -1: occur before first period\n",
    "    # -2: occur after last period\n",
    "    # 0: within period but not included\n",
    "for index, row in covid_data.iterrows():\n",
    "    true_period = np.NaN\n",
    "    if row['date'] < period_list[0][0]:\n",
    "        true_period = -1 # if occur before first period\n",
    "    elif row['date'] > period_list[-1][-1]:\n",
    "        true_period = -2 # if occur after last period\n",
    "    else: # else occur within a period\n",
    "        for period in period_list:\n",
    "            if period[0] <= row['date'] <= period[1]:\n",
    "                true_period = period_list.index(period) + 1\n",
    "    time_periods.append(true_period)\n",
    "# Add Time Period column to covid_data\n",
    "covid_data['Period'] = time_periods\n",
    "\n",
    "# Make a copy before cleaning\n",
    "data = covid_data.copy()\n",
    "\n",
    "# Remove rows with invalid time periods\n",
    "data.drop(data.loc[data['Period'] == -1].index, inplace=True)\n",
    "data.drop(data.loc[data['Period'] == -2].index, inplace=True)\n",
    "data.drop(data.loc[data['Period'] == np.NaN].index, inplace=True)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NaN and groupby Time Period for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty list to fill with each state's cleaned data\n",
    "clean_data = []\n",
    "\n",
    "# set death equal to max from death and deathConfirmed\n",
    "data[\"death\"] = data[[\"death\", \"deathConfirmed\"]].max(axis=1)\n",
    "# set positiveCasesViral equal to max from positiveCasesViral,totalTestsViral, and totalTestsPeopleViral\n",
    "data[\"positiveCasesViral\"] = data[[\"positiveCasesViral\", \"totalTestsViral\", \"totalTestsPeopleViral\"]].max(axis=1)\n",
    "# drop redundant columns\n",
    "clean_df = data.drop(columns=[\"deathConfirmed\", \"totalTestsViral\", \"totalTestsPeopleViral\"], axis=1)\n",
    "\n",
    "for state in final_states:\n",
    "    state_data = clean_df.loc[clean_df['state'] == state].reset_index(drop=True)\n",
    "    # Convert cumulative columns -> increase-by columns\n",
    "    # by calculating difference of the day prior from each day\n",
    "    state_data['deathIncrease'] = state_data['death'].diff(+1)\n",
    "    state_data['positiveTestsViralIncrease'] = state_data['positiveTestsViral'].diff(+1)\n",
    "    state_data['positiveCasesIncrease'] = state_data['positiveCasesViral'].diff(+1)\n",
    "    # Positivity Rate interaction term\n",
    "    state_data[\"positivityRate\"] = state_data[\"positiveTestsViralIncrease\"] / state_data[\"totalTestsPeopleViralIncrease\"]\n",
    "    # drop redundant columns\n",
    "    state_data = state_data.drop(columns=['totalTestsPeopleViralIncrease'], axis=1)\n",
    "    # replace inf with 1\n",
    "    state_data = state_data.replace(math.inf, 1)\n",
    "    state_data = state_data.replace(-math.inf, 1)\n",
    "    # replace null positivity rates with 0\n",
    "    state_data[\"positivityRate\"] = state_data[\"positivityRate\"].replace(np.NaN, 0)\n",
    "    \n",
    "    # reduce dimensionality from days to periods\n",
    "    state_data = state_data.groupby(['Period', 'state']).mean().reset_index()\n",
    "    clean_data.append(state_data)\n",
    "\n",
    "# combine states to final df\n",
    "clean_df = pd.concat(clean_data)\n",
    "# drop rows with null values\n",
    "ignore_columns = ['Period', 'state','positiveTestsViral', 'positiveTestsViralIncrease']\n",
    "drop_by_columns = [item for item in list(clean_df.columns) if item not in ignore_columns]\n",
    "clean_df = clean_df.dropna(subset=drop_by_columns)\n",
    "covid_df = clean_df.copy()\n",
    "covid_df['State'] = covid_df['state']\n",
    "covid_df = covid_df.drop('state', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.to_csv(\"Clean_Data/clean_covid_data.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Anxiety/Depression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = anxiety_depression_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove demographic rows and uneeded columns\n",
    "clean_data = data.loc[data['State'] != 'United States']\n",
    "clean_data = clean_data.drop(['Phase', 'Group', 'Subgroup', 'Time Period Label',\n",
    "                             'Low CI', 'High CI', 'Confidence Interval', 'Quartile range'], axis=1)\n",
    "\n",
    "# Break each target into a unique dataframe\n",
    "depression_data = clean_data.loc[clean_data['Indicator'] == 'Symptoms of Depressive Disorder']\n",
    "anxiety_data = clean_data.loc[clean_data['Indicator'] == 'Symptoms of Anxiety Disorder']\n",
    "both_data = clean_data.loc[clean_data['Indicator'] == 'Symptoms of Anxiety Disorder or Depressive Disorder']\n",
    "\n",
    "# Merge each target back into one dataframe on State and Time Period\n",
    "# Each target now is displayed in a column, and the height of the column is divided by 3\n",
    "merged_data = pd.merge(depression_data, anxiety_data, on=['State', 'Time Period'])\n",
    "merged_data = pd.merge(merged_data, both_data, on=['State', 'Time Period'])\n",
    "\n",
    "# Clean final dataframe\n",
    "merged_data = merged_data.drop(['Indicator_x', 'Indicator_y', 'Indicator'], axis=1)\n",
    "merged_data.columns = ['State', 'Period', 'Depression_Score', 'Anxiety_Score', 'Mix_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of states, used to change name -> acronym\n",
    "states_hash = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Federated States Of Micronesia': 'FM',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Marshall Islands': 'MH',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': ' ',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands': 'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Palau': 'PW',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change state name into acronym\n",
    "merged_data['State'] = merged_data.apply(lambda x: states_hash[x['State']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = merged_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.to_csv(\"Clean_Data/clean_label_data.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge predictor and response datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = response_df + covid_df + trip_df\n",
    "final_df = pd.merge(response_df, covid_df, on=['Period', 'State'])\n",
    "final_df = pd.merge(final_df, trip_df, on=['Period', 'State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired column order 'positivityRate', 'positiveCasesIncrease', 'positiveTestsViralIncrease', \n",
    "columns = ['State', 'Period', 'Mix_Score', 'Depression_Score', 'Anxiety_Score',\n",
    "           'deathIncrease', 'death', 'hospitalizedCurrently', \n",
    "           'positivityRate',\n",
    "           'positiveTestsViralIncrease', 'positiveTestsViral',\n",
    "           'positiveCasesIncrease', 'positiveCasesViral',\n",
    "           'Population Staying at Home', 'Population Not Staying at Home',\n",
    "           'Number of Trips', 'Number of Trips <1', 'Number of Trips 1-3',\n",
    "           'Number of Trips 3-5', 'Number of Trips 5-10', 'Number of Trips 10-25',\n",
    "           'Number of Trips 25-50', 'Number of Trips 50-100',\n",
    "           'Number of Trips 100-250', 'Number of Trips 250-500',\n",
    "           'Number of Trips >=500']\n",
    "final_df = final_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "statePop = pd.read_csv(\"StatePop.csv\") # state populations\n",
    "# turn state name into acronym\n",
    "statePop['State'] = statePop.apply(lambda x: states_hash[x['State']], axis=1)\n",
    "# add population column to final_df\n",
    "final_df = pd.merge(final_df, statePop, how='inner', on=['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of feature column names 'positivityRate',\n",
    "features = list(final_df.columns)\n",
    "for col in ['State', 'Period', 'Depression_Score', 'Anxiety_Score', 'Mix_Score', ]:\n",
    "    features.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features by population, except positivtyRate\n",
    "normalized_df = final_df.copy()\n",
    "for feature in features:\n",
    "    normalized_df.loc[:,feature] = normalized_df.loc[:,feature]/final_df['Pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop redundant columns\n",
    "normalized_df = normalized_df.drop(columns=[\"Pop\", \"density\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df.to_csv(\"Clean_Data/final_data.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
